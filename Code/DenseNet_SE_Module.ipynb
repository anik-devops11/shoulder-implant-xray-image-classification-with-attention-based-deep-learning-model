{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class and subclass names\n",
    "class_names = ['Cofield','Tornier','Zimmer','Depuy']\n",
    "\n",
    "# Initialize empty lists to store the image paths and labels\n",
    "X_train = []\n",
    "y_class_train = []\n",
    "X_val = []\n",
    "y_class_val = []\n",
    "X_test = []\n",
    "y_class_test = []\n",
    "\n",
    "\n",
    "# Loop through each class and subclass folder and append the image paths and labels to the lists\n",
    "for i, class_name in enumerate(class_names):\n",
    "  # Get the train image paths and labels\n",
    "  train_image_paths = tf.io.gfile.glob('/content/drive/MyDrive/dataset/' + '/train/' + class_name + '/*.jpg')\n",
    "  train_class_labels = [i] * len(train_image_paths)\n",
    "  X_train.extend(train_image_paths)\n",
    "  y_class_train.extend(train_class_labels)\n",
    "  # Get the val image paths and labels\n",
    "  val_image_paths = tf.io.gfile.glob('/content/drive/MyDrive/dataset/' + '/val/' + class_name + '/*.jpg')\n",
    "  val_class_labels = [i] * len(val_image_paths)\n",
    "  X_val.extend(val_image_paths)\n",
    "  y_class_val.extend(val_class_labels)\n",
    "  # Get the test image paths and labels\n",
    "  test_image_paths = tf.io.gfile.glob('/content/drive/MyDrive/dataset/' + '/test/' + class_name + '/*.jpg')\n",
    "  test_class_labels = [i] * len(test_image_paths)\n",
    "  X_test.extend(test_image_paths)\n",
    "  y_class_test.extend(test_class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the class names and their shape\n",
    "print(\"Class names:\", class_names)\n",
    "print(\"Shape of class names:\", np.array(class_names).shape)\n",
    "\n",
    "\n",
    "# Print the shapes of the training, validation, and test datasets\n",
    "print(\"Shape of X_train:\", np.array(X_train).shape)\n",
    "print(\"Shape of y_class_train:\", np.array(y_class_train).shape)\n",
    "print(\"Shape of X_val:\", np.array(X_val).shape)\n",
    "print(\"Shape of y_class_val:\", np.array(y_class_val).shape)\n",
    "print(\"Shape of X_test:\", np.array(X_test).shape)\n",
    "print(\"Shape of y_class_test:\", np.array(y_class_test).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class names: ['Cofield', 'Tornier', 'Zimmer', 'Depuy']\n",
    "Shape of class names: (4,)\n",
    "Shape of X_train: (477,)\n",
    "Shape of y_class_train: (477,)\n",
    "Shape of X_val: (58,)\n",
    "Shape of y_class_val: (58,)\n",
    "Shape of X_test: (62,)\n",
    "Shape of y_class_test: (62,)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
